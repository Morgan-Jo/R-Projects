labs(title = "Distribution of Final Grades (G3)", x = "Final Grade", y = "Count")
# Correlation matrix with G3
numeric_df <- df %>% select_if(is.numeric)
cor_matrix <- correlate(numeric_df)
cor_matrix %>% focus(G3) %>% arrange(desc(abs(G3)))
# Study time vs G3
ggplot(df, aes(x = factor(studytime), y = G3)) +
geom_boxplot(fill = "skyblue") +
labs(title = "Study Time vs Final Grade", x = "Study Time (1-4)", y = "Final Grade")
# Absences vs G3
ggplot(df, aes(x = absences, y = G3)) +
geom_point(alpha = 0.5, color = "tomato") +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Absences vs Final Grade", x = "Absences", y = "Final Grade")
# Select relevant features
model_data <- df %>%
select(G3, studytime, absences, failures, Medu, Fedu)
# Linear model feature importance
set.seed(42)
lm_model <- train(G3 ~ ., data = model_data, method = "lm")
varImp(lm_model)
# Split into training and test sets
set.seed(123)
trainIndex <- createDataPartition(df$G3, p = 0.8, list = FALSE)
train_data <- df[trainIndex, ]
test_data <- df[-trainIndex, ]
# Build linear regression model
lm_model <- train(G3 ~ studytime + absences + failures + Medu + Fedu, data = train_data, method = "lm")
# Predict and evaluate
predictions <- predict(lm_model, newdata = test_data)
postResample(predictions, test_data$G3)
# Create binary label
df$pass <- as.factor(ifelse(df$G3 >= 10, "yes", "no"))
# Train logistic regression model
log_model <- train(pass ~ studytime + absences + failures + Medu + Fedu,
data = df, method = "glm", family = "binomial")
# Predict and evaluate
preds <- predict(log_model, newdata = df)
confusionMatrix(preds, df$pass)
# Load libraries
library(tidyverse)
library(caret)
library(corrr)
library(ggplot2)
# Load math student performance dataset
df <- read.csv("student-mat.csv", sep = ";")
# Summary of the dataset
summary(df)
str(df)
# Distribution of final grades
ggplot(df, aes(x = G3)) +
geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
labs(title = "Distribution of Final Grades (G3)", x = "Final Grade", y = "Count")
# Correlation with numeric variables
numeric_df <- df %>% select_if(is.numeric)
cor_matrix <- correlate(numeric_df)
cor_matrix %>% focus(G3) %>% arrange(desc(abs(G3)))
# Study Time vs Final Grade
ggplot(df, aes(x = factor(studytime), y = G3)) +
geom_boxplot(fill = "skyblue") +
labs(title = "Study Time vs Final Grade", x = "Study Time (1-4)", y = "Final Grade")
# Absences vs Final Grade
ggplot(df, aes(x = absences, y = G3)) +
geom_point(alpha = 0.5, color = "tomato") +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Absences vs Final Grade", x = "Absences", y = "Final Grade")
# Check variable importance with linear model
model_data <- df %>%
select(G3, studytime, absences, failures, Medu, Fedu)
set.seed(42)
lm_model <- train(G3 ~ ., data = model_data, method = "lm")
varImp(lm_model)
# Split data
set.seed(123)
trainIndex <- createDataPartition(df$G3, p = 0.8, list = FALSE)
train_data <- df[trainIndex, ]
test_data <- df[-trainIndex, ]
# Model
lm_model <- train(G3 ~ studytime + absences + failures + Medu + Fedu, data = train_data, method = "lm")
# Predict and Evaluate
predictions <- predict(lm_model, newdata = test_data)
postResample(predictions, test_data$G3)
# Create binary outcome
df$pass <- ifelse(df$G3 >= 10, "yes", "no")
df$pass <- as.factor(df$pass)
# Model
log_model <- train(pass ~ studytime + absences + failures + Medu + Fedu,
data = df, method = "glm", family = "binomial")
# Confusion Matrix
preds <- predict(log_model, newdata = df)
confusionMatrix(preds, df$pass)
setwd("~/Work/Github/R - Project/Bike Sharing")
# ðŸ“¦ Load Libraries
library(tidyverse)
library(lubridate)
library(caret)
library(xgboost)
library(corrplot)
# ðŸ“ Load Dataset
day <- read.csv("day.csv")
# ðŸ§¼ Preprocessing
day$dteday <- as.Date(day$dteday)
day$season <- factor(day$season, labels = c("Winter", "Spring", "Summer", "Fall"))
day$weekday <- factor(day$weekday, labels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"))
# ðŸ‘ï¸ EDA - Correlation Plot
numeric_cols <- day %>% select(temp, atemp, hum, windspeed, casual, registered, cnt)
corrplot(cor(numeric_cols), method = "color", type = "lower", tl.col = "black")
# ðŸ“Š Visualizations
ggplot(day, aes(x = dteday, y = cnt)) +
geom_line(color = "blue") +
labs(title = "Daily Total Rentals", x = "Date", y = "Total Rentals")
ggplot(day, aes(x = temp, y = cnt)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm") +
labs(title = "Temperature vs Rentals")
# ðŸ§  Feature Engineering
day$month <- month(day$dteday)
day$day_of_week <- wday(day$dteday, label = TRUE)
# âœ‚ï¸ Split Data
set.seed(123)
index <- createDataPartition(day$cnt, p = 0.8, list = FALSE)
train_data <- day[index, ]
test_data <- day[-index, ]
# ðŸ§ª Model Training: XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data %>% select(temp, hum, windspeed, season, workingday)),
label = train_data$cnt)
# ðŸ“ˆ Predictions & Evaluation
preds <- predict(xgb_model, test_matrix)
train_matrix <- xgb.DMatrix(data = as.matrix(train_data %>% select(temp, hum, windspeed, season, hr, workingday, holiday, weathersit)),
label = train_data$cnt)
# Load libraries
library(tidyverse)
library(lubridate)
library(caret)
library(xgboost)
library(Metrics)
library(ggplot2)
Metrics::rmse(actual, predicted)
Metrics::rmse(actual, predicted)
# Load required libraries
library(tidyverse)
library(lubridate)
library(caret)
library(xgboost)
library(Metrics)
library(ggplot2)
# Load the dataset
bike_data <- read.csv("day.csv")
# Inspect data
glimpse(bike_data)
# Convert date to Date type and extract datetime features
bike_data$dteday <- as.Date(bike_data$dteday)
bike_data$day <- day(bike_data$dteday)
bike_data$month <- month(bike_data$dteday)
bike_data$year <- year(bike_data$dteday)
bike_data$weekday <- wday(bike_data$dteday, label = TRUE)
# Drop unused columns
bike_data <- bike_data %>% select(-instant, -casual, -registered)
# Train-Test Split (80-20)
set.seed(123)
train_index <- createDataPartition(bike_data$cnt, p = 0.8, list = FALSE)
train_data <- bike_data[train_index, ]
test_data <- bike_data[-train_index, ]
# Train a linear regression model
lm_model <- train(cnt ~ ., data = train_data, method = "lm")
lm_pred <- predict(lm_model, newdata = test_data)
lm_rmse <- rmse(test_data$cnt, lm_pred)
# Prepare data for XGBoost
train_matrix <- model.matrix(cnt ~ . -1, data = train_data)
test_matrix <- model.matrix(cnt ~ . -1, data = test_data)
dtrain <- xgb.DMatrix(data = train_matrix, label = train_data$cnt)
dtest <- xgb.DMatrix(data = test_matrix, label = test_data$cnt)
# Train XGBoost model
xgb_model <- xgboost(data = dtrain, nrounds = 100, objective = "reg:squarederror", verbose = 0)
xgb_pred <- predict(xgb_model, dtest)
xgb_rmse <- rmse(test_data$cnt, xgb_pred)
# Model Performance
cat("Linear Regression RMSE:", round(lm_rmse, 2), "\n")
cat("XGBoost RMSE:", round(xgb_rmse, 2), "\n")
# Plot predictions
results <- data.frame(Date = test_data$dteday, Actual = test_data$cnt,
LM_Predicted = lm_pred, XGB_Predicted = xgb_pred)
ggplot(results, aes(x = Date)) +
geom_line(aes(y = Actual, color = "Actual")) +
geom_line(aes(y = LM_Predicted, color = "Linear Regression")) +
geom_line(aes(y = XGB_Predicted, color = "XGBoost")) +
labs(title = "Bike Rentals: Actual vs Predicted", y = "Count", color = "Legend") +
theme_minimal()
library(shiny); runApp('Day_App.R')
runApp('Day_App.R')
colnames(results)
# Should return: "Date", "Actual", "Linear Regression", "XGBoost"
runApp('Day_App.R')
runApp('Day_App.R')
runApp('Day_App.R')
runApp('Day_App.R')
runApp('Day_App.R')
runApp('Day_App.R')
runApp('Day_App.R')
# ðŸ“¦ Load Libraries
library(tidyverse)
library(lubridate)
library(caret)
library(xgboost)
library(corrplot)
# ðŸ“ Load Dataset
hour <- read.csv("hour.csv")
# ðŸ§¼ Preprocessing
hour$dteday <- as.Date(hour$dteday)
hour$season <- factor(hour$season, labels = c("Winter", "Spring", "Summer", "Fall"))
hour$weekday <- factor(hour$weekday, labels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"))
hour$hr <- factor(hour$hr)  # treat hour as categorical for modeling
hour$weathersit <- factor(hour$weathersit, labels = c("Clear", "Mist", "Light Snow", "Heavy Rain"))
# ðŸ“Š Visualizations
# Rentals by Hour
ggplot(hour, aes(x = hr, y = cnt)) +
geom_boxplot(aes(fill = workingday)) +
labs(title = "Hourly Rental Count by Working Day", x = "Hour", y = "Count")
# Rentals by Temperature
ggplot(hour, aes(x = temp, y = cnt)) +
geom_point(alpha = 0.3) +
geom_smooth(method = "lm") +
labs(title = "Temperature vs Rentals", x = "Normalized Temp", y = "Rental Count")
# ðŸ‘ï¸ Correlation Analysis
numeric_vars <- hour %>% select(temp, atemp, hum, windspeed, casual, registered, cnt)
corrplot(cor(numeric_vars), method = "color", type = "lower", tl.col = "black")
# ðŸ§  Feature Engineering
hour$hour <- as.numeric(as.character(hour$hr))
hour$time_period <- case_when(
hour$hour >= 6 & hour$hour < 12 ~ "Morning",
hour$hour >= 12 & hour$hour < 18 ~ "Afternoon",
hour$hour >= 18 & hour$hour < 24 ~ "Evening",
TRUE ~ "Night"
)
hour$time_period <- factor(hour$time_period)
# âœ‚ï¸ Train-Test Split
set.seed(42)
index <- createDataPartition(hour$cnt, p = 0.8, list = FALSE)
train_data <- hour[index, ]
test_data <- hour[-index, ]
# ðŸ“¦ Prepare Matrix for XGBoost
features <- c("temp", "hum", "windspeed", "season", "hr", "workingday", "holiday", "weathersit")
train_matrix <- xgb.DMatrix(data = model.matrix(~ . -1, train_data[, features]), label = train_data$cnt)
test_matrix <- xgb.DMatrix(data = model.matrix(~ . -1, test_data[, features]), label = test_data$cnt)
# âš™ï¸ Train XGBoost Model
xgb_model <- xgboost(data = train_matrix, nrounds = 150, objective = "reg:squarederror", verbose = 0)
# ðŸ“ˆ Predict & Evaluate
preds <- predict(xgb_model, test_matrix)
rmse <- sqrt(mean((preds - test_data$cnt)^2))
print(paste("RMSE:", round(rmse, 2)))
# ðŸ“Š Feature Importance
importance <- xgb.importance(model = xgb_model)
xgb.plot.importance(importance_matrix = importance)
runApp()
# Load libraries
library(tidyverse)
library(lubridate)
library(caret)
library(xgboost)
library(Metrics)
# Load data
data <- read.csv("hour.csv")
# Feature engineering
data$datetime <- ymd_hms(data$dteday) + hours(data$hr)
data$hour <- hour(data$datetime)
data$day <- day(data$datetime)
data$month <- month(data$datetime)
data$wday <- wday(data$datetime, label = TRUE)
# Feature engineering
data$datetime <- ymd(data$dteday) + hours(data$hr)
# Select features
features <- data %>%
select(cnt, temp, hum, windspeed, season, holiday, workingday, weathersit, hour, month, wday)
# Train-test split
set.seed(123)
train_idx <- createDataPartition(features$cnt, p = 0.8, list = FALSE)
train_data <- features[train_idx, ]
test_data <- features[-train_idx, ]
# Linear regression model
lm_model <- train(cnt ~ ., data = train_data, method = "lm")
# Select features
features <- data %>%
select(cnt, temp, hum, windspeed, season, holiday, workingday, weathersit, hour, month, wday)
# âœ… Remove missing values
features <- na.omit(features)
# Train-test split
set.seed(123)
train_idx <- createDataPartition(features$cnt, p = 0.8, list = FALSE)
# Convert wday to numeric to prevent NA creation
data$wday <- as.numeric(wday(data$datetime, label = TRUE))
# Feature engineering and cleanup
features <- data %>%
select(cnt, temp, hum, windspeed, season, holiday, workingday, weathersit, hour, month, wday)
# Check and remove NAs
cat("Missing values per column:\n")
print(colSums(is.na(features)))
features <- na.omit(features)
cat("Rows after removing NAs:", nrow(features), "\n")
# Linear regression model
lm_model <- train(cnt ~ ., data = train_data, method = "lm")
# Load libraries
library(tidyverse)
library(lubridate)
library(caret)
library(xgboost)
library(Metrics)
# Load data
data <- read.csv("hour.csv")
# Feature engineering
data$datetime <- ymd(data$dteday) + hours(data$hr)
data$hour <- hour(data$datetime)
data$day <- day(data$datetime)
data$month <- month(data$datetime)
data$wday <- wday(data$datetime, label = TRUE)
# Select features
features <- data %>%
select(cnt, temp, hum, windspeed, season, holiday, workingday, weathersit, hour, month, wday)
# Train-test split
set.seed(123)
train_idx <- createDataPartition(features$cnt, p = 0.8, list = FALSE)
train_data <- features[train_idx, ]
test_data <- features[-train_idx, ]
# Linear regression model
lm_model <- train(cnt ~ ., data = train_data, method = "lm")
lm_preds <- predict(lm_model, newdata = test_data)
# XGBoost model
xgb_train <- xgb.DMatrix(data = as.matrix(train_data %>% select(-cnt)), label = train_data$cnt)
# XGBoost model
xgb_train <- xgb.DMatrix(data = as.matrix(sapply(train_data %>% select(-cnt), as.numeric)), label = train_data$cnt)
xgb_test <- xgb.DMatrix(data = as.matrix(sapply(test_data %>% select(-cnt), as.numeric)))
xgb_model <- xgboost(data = xgb_train, nrounds = 100, objective = "reg:squarederror", verbose = 0)
xgb_preds <- predict(xgb_model, xgb_test)
# Evaluate models
rmse_lm <- rmse(test_data$cnt, lm_preds)
rmse_xgb <- rmse(test_data$cnt, xgb_preds)
# Print RMSE results
print(paste("Linear Regression RMSE:", round(rmse_lm, 2)))
print(paste("XGBoost RMSE:", round(rmse_xgb, 2)))
# Visualization
results <- data.frame(
Date = test_data$hour,
Actual = test_data$cnt,
LM_Predicted = lm_preds,
XGB_Predicted = xgb_preds
)
results_long <- results %>%
pivot_longer(cols = c("Actual", "LM_Predicted", "XGB_Predicted"),
names_to = "Type", values_to = "Count")
ggplot(results_long, aes(x = Date, y = Count, color = Type)) +
geom_line() +
labs(title = "Bike Rental Prediction Comparison", x = "Hour", y = "Bike Count")
runApp('Hour-App.R')
setwd("~/Work/Github/R - Project/Stock Price Analysis")
# Load libraries
library(quantmod)
library(TTR)
library(PerformanceAnalytics)
library(ggplot2)
# Define stock symbols
stocks <- c("AAPL", "MSFT", "TSLA")
# Download data from Yahoo Finance
getSymbols(stocks, from = "2020-01-01", to = Sys.Date(), src = "yahoo")
# Use AAPL
stock_AAPL_data <- AAPL
stock_MSFT_data <- MSFT
stock_TSLA_data <- TSLA
# Plot adjusted close
chartSeries(stock_AAPL_data, type = "line", subset = "last 6 months", theme = chartTheme("white"))
chartSeries(stock_MSFT_data, type = "line", subset = "last 6 months", theme = chartTheme("white"))
chartSeries(stock_TSLA_data, type = "line", subset = "last 6 months", theme = chartTheme("white"))
# Calculate Daily Returns
daily_returns_AALP <- dailyReturn(Cl(stock_AAPL_data))
daily_returns_MSFT <- dailyReturn(Cl(stock_MSFT_data))
daily_returns_TSLA <- dailyReturn(Cl(stock_TSLA_data))
# Calculate Weekly Returns
weekly_returns_AALP <- weeklyReturn(Cl(stock_AAPL_data))
weekly_returns_MSFT <- weeklyReturn(Cl(stock_MSFT_data))
weekly_returns_TSLA <- weeklyReturn(Cl(stock_TSLA_data))
# Plot Daily Returns
plot(daily_returns_AALP, main = "Daily Returns - AAPL", col = "blue")
plot(daily_returns_MSFT, main = "Daily Returns - MSFT", col = "blue")
plot(daily_returns_TSLA, main = "Daily Returns - TSLA", col = "blue")
# Add Moving Averages and Bollinger Bands
#AAPL
stock_AAPL_data$SMA20 <- SMA(Cl(stock_AAPL_data), n = 20)
stock_AAPL_data$SMA50 <- SMA(Cl(stock_AAPL_data), n = 50)
bbands <- BBands(Cl(stock_AAPL_data), n = 20)
#MSFT
stock_MSFT_data$SMA20 <- SMA(Cl(stock_MSFT_data), n = 20)
stock_MSFT_data$SMA50 <- SMA(Cl(stock_MSFT_data), n = 50)
bbands <- BBands(Cl(stock_MSFT_data), n = 20)
#TSLA
stock_TSLA_data$SMA20 <- SMA(Cl(stock_TSLA_data), n = 20)
stock_TSLA_data$SMA50 <- SMA(Cl(stock_TSLA_data), n = 50)
bbands <- BBands(Cl(stock_TSLA_data), n = 20)
# Combine with stock data
#AAPL
stock_AAPL_data$BB_Upper <- bbands$up
stock_AAPL_data$BB_Lower <- bbands$dn
stock_AAPL_data$BB_Middle <- bbands$mavg
#MSFT
stock_MSFT_data$BB_Upper <- bbands$up
stock_MSFT_data$BB_Lower <- bbands$dn
stock_MSFT_data$BB_Middle <- bbands$mavg
#TSLA
stock_TSLA_data$BB_Upper <- bbands$up
stock_TSLA_data$BB_Lower <- bbands$dn
stock_TSLA_data$BB_Middle <- bbands$mavg
# Plot with indicators using quantmod
chartSeries(stock_AAPL_data, theme = chartTheme("white"), TA = c(addSMA(20), addSMA(50), addBBands(n = 20)))
chartSeries(stock_MSFT_data, theme = chartTheme("white"), TA = c(addSMA(20), addSMA(50), addBBands(n = 20)))
chartSeries(stock_TSLA_data, theme = chartTheme("white"), TA = c(addSMA(20), addSMA(50), addBBands(n = 20)))
# Simulate simple strategy: Buy if price < Lower BB, Sell if > Upper BB
#AAPL
signals_AAPL <- ifelse(Cl(stock_AAPL_data) < stock_AAPL_data$BB_Lower, 1,
ifelse(Cl(stock_APPL_data) > stock_AAPL_data$BB_Upper, -1, 0))
# Simulate simple strategy: Buy if price < Lower BB, Sell if > Upper BB
#AAPL
signals_AAPL <- ifelse(Cl(stock_AAPL_data) < stock_AAPL_data$BB_Lower, 1,
ifelse(Cl(stock_AAPL_data) > stock_AAPL_data$BB_Upper, -1, 0))
returns_AAPL <- dailyReturn(Cl(stock_AAPL_data)) * Lag(signals_AAPL)
#MSFT
signals_MSFT <- ifelse(Cl(stock_MSFTL_data) < stock_MSFT_data$BB_Lower, 1,
ifelse(Cl(stock_MSFT_data) > stock_MSFT_data$BB_Upper, -1, 0))
# Simulate simple strategy: Buy if price < Lower BB, Sell if > Upper BB
#AAPL
signals_AAPL <- ifelse(Cl(stock_AAPL_data) < stock_AAPL_data$BB_Lower, 1,
ifelse(Cl(stock_AAPL_data) > stock_AAPL_data$BB_Upper, -1, 0))
returns_AAPL <- dailyReturn(Cl(stock_AAPL_data)) * Lag(signals_AAPL)
#MSFT
signals_MSFT <- ifelse(Cl(stock_MSFT_data) < stock_MSFT_data$BB_Lower, 1,
ifelse(Cl(stock_MSFT_data) > stock_MSFT_data$BB_Upper, -1, 0))
returns_MSFT <- dailyReturn(Cl(stock_MSFT_data)) * Lag(signals_MSFT)
#TSLA
signals_TSLA <- ifelse(Cl(stock_TSLAL_data) < stock_TSLAL_data$BB_Lower, 1,
ifelse(Cl(stock_TSLA_data) > stock_TSLA_data$BB_Upper, -1, 0))
#TSLA
signals_TSLA <- ifelse(Cl(stock_TSLA_data) < stock_TSLAL_data$BB_Lower, 1,
ifelse(Cl(stock_TSLA_data) > stock_TSLA_data$BB_Upper, -1, 0))
#TSLA
signals_TSLA <- ifelse(Cl(stock_TSLA_data) < stock_TSLA_data$BB_Lower, 1,
ifelse(Cl(stock_TSLA_data) > stock_TSLA_data$BB_Upper, -1, 0))
returns_TSLA <- dailyReturn(Cl(stock_TSLA_data)) * Lag(signals_TSLA)
# Performance summary
charts.PerformanceSummary(na.omit(returns_AAPL), main = "Bollinger Band Strategy Returns AAPL")
charts.PerformanceSummary(na.omit(returns_MSFT), main = "Bollinger Band Strategy Returns MSFT")
charts.PerformanceSummary(na.omit(returns_TSLA), main = "Bollinger Band Strategy Returns TSLA")
# ggplot2 Visualization of Adjusted Close
df1 <- data.frame(Date = index(stock__AAPLdata), coredata(stock_AAPL_data))
# ggplot2 Visualization of Adjusted Close
df1 <- data.frame(Date = index(stock__AAPL_data), coredata(stock_AAPL_data))
# ggplot2 Visualization of Adjusted Close
df1 <- data.frame(Date = index(stock_AAPL_data), coredata(stock_AAPL_data))
ggplot(df1, aes(x = Date)) +
geom_line(aes(y = AAPL.Adjusted), color = "steelblue") +
geom_line(aes(y = SMA20), color = "red", linetype = "dashed") +
geom_line(aes(y = SMA50), color = "darkgreen", linetype = "dashed") +
labs(title = "AAPL Price with Moving Averages", y = "Price", x = "")
# ggplot2 Visualization of Adjusted Close
df1 <- data.frame(Date = index(stock_AAPL_data), coredata(stock_AAPL_data))
df1_clean <- na.omit(df)
ggplot(df1_clean, aes(x = Date)) +
geom_line(aes(y = AAPL.Adjusted), color = "steelblue") +
geom_line(aes(y = SMA20), color = "red", linetype = "dashed") +
geom_line(aes(y = SMA50), color = "darkgreen", linetype = "dashed") +
labs(title = "AAPL Price with Moving Averages", y = "Price", x = "")
# ggplot2 Visualization of Adjusted Close
df1 <- data.frame(Date = index(stock_AAPL_data), coredata(stock_AAPL_data))
df1_clean <- na.omit(df)
ggplot(data=df1_clean, aes(x = Date)) +
geom_line(aes(y = AAPL.Adjusted), color = "steelblue") +
geom_line(aes(y = SMA20), color = "red", linetype = "dashed") +
geom_line(aes(y = SMA50), color = "darkgreen", linetype = "dashed") +
labs(title = "AAPL Price with Moving Averages", y = "Price", x = "")
df1 <- data.frame(Date = index(stock_AAPL_data), coredata(stock_AAPL_data))
df1_clean <- na.omit(df1)
ggplot(data=df1_clean, aes(x = Date)) +
geom_line(aes(y = AAPL.Adjusted), color = "steelblue") +
geom_line(aes(y = SMA20), color = "red", linetype = "dashed") +
geom_line(aes(y = SMA50), color = "darkgreen", linetype = "dashed") +
labs(title = "AAPL Price with Moving Averages", y = "Price", x = "")
#MSFT
df2 <- data.frame(Date = index(stock_MSFT_data), coredata(stock_MSFT_data))
df2_clean <- na.omit(df2)
ggplot(data=df2_clean, aes(x = Date)) +
geom_line(aes(y = AAPL.Adjusted), color = "steelblue") +
geom_line(aes(y = SMA20), color = "red", linetype = "dashed") +
geom_line(aes(y = SMA50), color = "darkgreen", linetype = "dashed") +
labs(title = "MSFT Price with Moving Averages", y = "Price", x = "")
#MSFT
df2 <- data.frame(Date = index(stock_MSFT_data), coredata(stock_MSFT_data))
df2_clean <- na.omit(df2)
ggplot(data=df2_clean, aes(x = Date)) +
geom_line(aes(y = MSFT.Adjusted), color = "steelblue") +
geom_line(aes(y = SMA20), color = "red", linetype = "dashed") +
geom_line(aes(y = SMA50), color = "darkgreen", linetype = "dashed") +
labs(title = "MSFT Price with Moving Averages", y = "Price", x = "")
#TSLA
df3 <- data.frame(Date = index(stock_TSLAL_data), coredata(stock_TSLA_data))
#TSLA
df3 <- data.frame(Date = index(stock_TSLA_data), coredata(stock_TSLA_data))
df3_clean <- na.omit(df3)
ggplot(data=df3_clean, aes(x = Date)) +
geom_line(aes(y = TSLA.Adjusted), color = "steelblue") +
geom_line(aes(y = SMA20), color = "red", linetype = "dashed") +
geom_line(aes(y = SMA50), color = "darkgreen", linetype = "dashed") +
labs(title = "TSLA Price with Moving Averages", y = "Price", x = "")
# Plot Weekly Returns
plot(weekly_returns_AALP, main = "Weekly Returns - AAPL", col = "blue")
plot(weekly_returns_MSFT, main = "Weekly Returns - MSFT", col = "blue")
plot(weekdly_returns_TSLA, main = "Weekly Returns - TSLA", col = "blue")
plot(weekly_returns_TSLA, main = "Weekly Returns - TSLA", col = "blue")
